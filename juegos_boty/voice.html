<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Boty Live - Conversación Real</title>
<style>
  :root { --bg: #000; --accent: #00ffcc; --dim: #003322; }
  body { font-family: 'Inter', sans-serif; background: var(--bg); color: var(--accent); display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; overflow: hidden; }
  
  #orb {
    width: 200px; height: 200px; border-radius: 50%;
    background: radial-gradient(circle, var(--accent) 0%, transparent 70%);
    box-shadow: 0 0 50px var(--accent);
    transition: all 0.3s ease;
    opacity: 0.3;
    cursor: pointer;
  }
  
  #orb.talking {
    animation: pulse 0.5s infinite alternate;
    opacity: 1;
    transform: scale(1.1);
  }

  #orb.listening {
    opacity: 0.8;
    box-shadow: 0 0 100px var(--accent);
    animation: breathe 3s infinite ease-in-out;
  }

  @keyframes pulse {
    from { transform: scale(1.1); box-shadow: 0 0 50px var(--accent); }
    to { transform: scale(1.3); box-shadow: 0 0 120px var(--accent); }
  }

  @keyframes breathe {
    0%, 100% { transform: scale(1); opacity: 0.5; }
    50% { transform: scale(1.05); opacity: 0.8; }
  }

  #status { margin-top: 40px; font-size: 1rem; font-weight: bold; letter-spacing: 3px; text-transform: uppercase; }
  #transcript { margin-top: 20px; font-style: italic; opacity: 0.5; max-width: 80%; text-align: center; font-size: 0.9rem; min-height: 1.2em; }
  
  .hint { position: fixed; bottom: 20px; font-size: 0.7rem; opacity: 0.3; }
</style>
</head>
<body>

<div id="orb"></div>
<div id="status">TOCA PARA CONECTAR</div>
<div id="transcript">Listo para la conversación</div>
<div class="hint">Boty Core v3.3 | Proxy Hybrid Active</div>

<script>
const orb = document.getElementById('orb');
const status = document.getElementById('status');
const transcript = document.getElementById('transcript');

let isBotSpeaking = false;
let recognition;

if ('webkitSpeechRecognition' in window) {
  recognition = new webkitSpeechRecognition();
  recognition.continuous = true;
  recognition.interimResults = false;
  recognition.lang = 'es-ES';

  recognition.onstart = () => {
    if (!isBotSpeaking) {
      status.textContent = "TE ESCUCHO";
      orb.className = 'listening';
    }
  };

  recognition.onresult = async (event) => {
    if (isBotSpeaking) return;
    const text = event.results[event.results.length - 1][0].transcript.trim();
    if (text.length < 2) return;
    transcript.textContent = text;
    recognition.stop();
    await chatWithBoty(text);
  };

  recognition.onend = () => {
    if (!isBotSpeaking) {
      try { recognition.start(); } catch(e) {}
    }
  };
}

document.body.addEventListener('click', () => {
  try {
    recognition.start();
    status.textContent = "SISTEMA ACTIVO";
  } catch(e) { console.log("Ya iniciado"); }
}, { once: true });

async function chatWithBoty(text) {
  isBotSpeaking = true;
  status.textContent = "PENSANDO...";
  orb.className = '';

  try {
    // Usamos el Proxy de Python (puerto 8081) para evitar el bloqueo de CORS del Gateway
    const resp = await fetch('/api/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ message: text })
    });
    
    if (!resp.ok) throw new Error("Proxy error: " + resp.status);
    
    const data = await resp.json();
    // Si el proxy devuelve una respuesta real (no el placeholder), hablamos
    await speakWithEleven(data.reply);

  } catch (e) {
    console.error("Error chat:", e);
    status.textContent = "ERROR DE CONEXIÓN";
    isBotSpeaking = false;
    setTimeout(() => { if (!isBotSpeaking) recognition.start(); }, 2000);
  }
}

async function speakWithEleven(text) {
  const ELEVEN_API_KEY = 'sk_339ff3d71baaa6ddd514251fdfec5766199378762ad5e200';
  const VOICE_ID = 'pNInz6obpgDQGcFmaJgB';
  
  try {
    const ttsResp = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}/stream`, {
      method: 'POST',
      headers: {
        'Accept': 'audio/mpeg',
        'Content-Type': 'application/json',
        'xi-api-key': ELEVEN_API_KEY
      },
      body: JSON.stringify({
        text: text,
        model_id: 'eleven_multilingual_v2',
        voice_settings: { stability: 0.4, similarity_boost: 0.8 }
      })
    });

    const blob = await ttsResp.blob();
    const audio = new Audio(URL.createObjectURL(blob));
    
    audio.onplay = () => {
      status.textContent = "BOTY HABLANDO";
      orb.className = 'talking';
    };

    audio.onended = () => {
      isBotSpeaking = false;
      orb.className = 'listening';
      status.textContent = "TE ESCUCHO";
      try { recognition.start(); } catch(e) {}
    };

    audio.play();

  } catch (e) {
    console.error("Error TTS:", e);
    isBotSpeaking = false;
    try { recognition.start(); } catch(e) {}
  }
}
</script>
</body>
</html>
